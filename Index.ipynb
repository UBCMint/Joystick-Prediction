{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akirakudo901/Joystick-Prediction/blob/feature_extraction/Index.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJhkLkR-lfsU"
      },
      "source": [
        "# ECoG Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5rTOOUGlfsX"
      },
      "source": [
        "## Downloading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RE0Mu4AglfsY"
      },
      "outputs": [],
      "source": [
        "from matplotlib import rcParams\n",
        "from matplotlib import pyplot as plt\n",
        "import os, requests\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "from scipy import signal, fft\n",
        "import matplotlib.animation as animation\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvlpErMglfsa"
      },
      "outputs": [],
      "source": [
        "fname = 'joystick_track.npz'\n",
        "url = \"https://osf.io/6jncm/download\"\n",
        "\n",
        "if not os.path.isfile(fname):\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "  except requests.ConnectionError:\n",
        "    print(\"!!! Failed to download data !!!\")\n",
        "  else:\n",
        "    if r.status_code != requests.codes.ok:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      with open(fname, \"wb\") as fid:\n",
        "        fid.write(r.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9DFaNhFlfsa"
      },
      "outputs": [],
      "source": [
        "rcParams['figure.figsize'] = [20, 4]\n",
        "rcParams['font.size'] = 15\n",
        "rcParams['axes.spines.top'] = False\n",
        "rcParams['axes.spines.right'] = False\n",
        "rcParams['figure.autolayout'] = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scwrCWHTlfsb"
      },
      "source": [
        "## Dataset info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VMeByOXlfsb"
      },
      "source": [
        "\n",
        "This is one of multiple ECoG datasets from Miller 2019, recorded in clinical settings with a variety of tasks. Raw data here:\n",
        "\n",
        "https://exhibits.stanford.edu/data/catalog/zk881ps0522\n",
        "\n",
        "`dat` contain 4 sessions from 4 subjects, and was used in these papers:\n",
        "\n",
        "- Schalk, G., et al. \"Decoding two-dimensional movement trajectories using electrocorticographic signals in humans.\" Journal of Neural Engineering 4.3 (2007): 264. doi: [10.1088/1741-2560/4/3/012](https://doi.org/10.1088/1741-2560/4/3/012)\n",
        "\n",
        "- Schalk, Gerwin, et al. \"Two-dimensional movement control using electrocorticographic signals in humans.\" Journal of Neural Engineering 5.1 (2008): 75. doi: [10.1088/1741-2560/5/1/008](https://doi.org/10.1088/1741-2560/5/1/008)\n",
        "\n",
        "<br>\n",
        "\n",
        "From the dataset readme:\n",
        "\n",
        "*During the study, each patient was in a semi-recumbent position in a hospital bed about 1 m from a computer monitor. The patient used a joystick to maneuver a white cursor track a green target moving counter-clockwise in a circle of diameter 85% of monitor height ~1m away. The hand used to control the joystick was contralateral to the implanted electrode array.*\n",
        "\n",
        "<br>\n",
        "\n",
        "We also know that subject 0 was implanted in the left temporal lobe, while subject 2 was implanted in the right frontal lobe.\n",
        "\n",
        "Sample rate is always 1000Hz, and the ECoG data has been notch-filtered at 60, 120, 180, 240 and 250Hz, followed by z-scoring across the entire recording and conversion to float16 to minimize size.\n",
        "\n",
        "Variables are:\n",
        "* `dat['V']`: continuous voltage data (time by channels)\n",
        "* `dat['targetX']`: position of the target on the screen\n",
        "* `dat['targetY']`: position of the target on the screen\n",
        "* `dat['cursorX']`: X position of the cursor controlled by the joystick\n",
        "* `dat['cursorY']`: X position of the cursor controlled by the joystick\n",
        "* `dat['locs`]: three-dimensional coordinates of the electrodes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74-rTHZXlfsb"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKHviLK3lfsb"
      },
      "outputs": [],
      "source": [
        "# DEFINING USEFUL CONSTANTS\n",
        "SAMPLE_RATE = 1000\n",
        "# By checking cursor sample rate in \"Identifying sample ...\" below, we figured\n",
        "# the sample rate of cursor on screen was identified every 40 time points\n",
        "TIMEPOINTS_PER_CURSOR_UPDATE = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9idUHnrlfsb"
      },
      "outputs": [],
      "source": [
        "alldat = np.load(fname, allow_pickle=True)['dat']\n",
        "print(\"Shape of alldat:\", alldat.shape)\n",
        "\n",
        "# Select just one of the recordings here. This is subject 1, block 1.\n",
        "dat = alldat[0][0]\n",
        "print(dat.keys())\n",
        "print(\"Shape of V:\", dat['V'].shape)\n",
        "print(\"Shape of targetX:\", dat['targetX'].shape)\n",
        "print(\"Shape of targetY:\", dat['targetY'].shape)\n",
        "print(\"Shape of cursorX:\", dat['cursorX'].shape)\n",
        "print(\"Shape of cursorY:\", dat['cursorY'].shape)\n",
        "\n",
        "plt.plot(dat['V'][:, 0])\n",
        "plt.title(\"first voltage channel for subject 1, session 1\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jbbbg4_Xlfsc"
      },
      "outputs": [],
      "source": [
        "PATIENT_NUMBER = 0\n",
        "\n",
        "dat = alldat[0][PATIENT_NUMBER]\n",
        "V = dat['V'].astype('float16')\n",
        "\n",
        "nt, nchan = V.shape\n",
        "\n",
        "plt.plot(V)\n",
        "plt.xlabel('Time (10e-3s)')\n",
        "plt.ylabel(f'Norm V for P: {PATIENT_NUMBER}')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eQ-i9zalfsc"
      },
      "outputs": [],
      "source": [
        "# Author: Akira Kudo\n",
        "# Created: -\n",
        "# Last updated: 2024/03/10\n",
        "\n",
        "def datatype_per_patient(patient_num):\n",
        "  print(f\"PATIENT {i}\")\n",
        "  patient = alldat[0][patient_num]\n",
        "  printed = \" \".join(\n",
        "      [f\"({k} : {patient[k].dtype})\" if isinstance(patient[k], np.ndarray) else \"\"\n",
        "      for k in patient.keys()])\n",
        "  print(printed)\n",
        "\n",
        "\n",
        "print(\"DATATYPE:\")\n",
        "for i in range(len(alldat[0])):\n",
        "  datatype_per_patient(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clGfNStKlfsc"
      },
      "outputs": [],
      "source": [
        "# Author: Akira Kudo\n",
        "# Created: -\n",
        "# Last updated: 2024/03/10\n",
        "\n",
        "def description_for_patient_i(i):\n",
        "  print(f\"FOR PATIENT {i}:\")\n",
        "  patient = alldat[0][i]\n",
        "\n",
        "  assert(patient['V'].shape[0]       == patient['targetX'].shape[0] and\n",
        "         patient['targetX'].shape[0] == patient['targetY'].shape[0] and\n",
        "         patient['targetY'].shape[0] == patient['cursorX'].shape[0] and\n",
        "         patient['cursorX'].shape[0] == patient['cursorY'].shape[0])\n",
        "\n",
        "  assert(patient['targetX'].shape[1] == 1 and\n",
        "         patient['targetY'].shape[1] == 1 and\n",
        "         patient['cursorX'].shape[1] == 1 and\n",
        "         patient['cursorY'].shape[1] == 1)\n",
        "\n",
        "  assert(patient['V'].shape[1] == patient['locs'].shape[0])\n",
        "\n",
        "  num_timepoints, num_channels = patient['V'].shape\n",
        "  print(f\" - Voltage data has {num_timepoints} timepoints and {num_channels} channels.\")\n",
        "\n",
        "  print(f\" - Locations of {num_channels} electrodes expressed in {patient['locs'].shape[1]}D.\")\n",
        "\n",
        "  for category_label in ['hemisphere', 'lobe', 'gyrus', 'Brodmann_Area']:\n",
        "    unique_labels = np.unique(patient[category_label])\n",
        "    print(f\" - Unique labels for {category_label}: \\n{unique_labels}.\")\n",
        "\n",
        "  print(\"___________________________________\")\n",
        "\n",
        "\n",
        "num_patients = len(alldat[0])\n",
        "# print(f\"We have {num_patients} patients in this dataset.\")\n",
        "\n",
        "for i in range(num_patients):\n",
        "  description_for_patient_i(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JH6-z2E2lfsd"
      },
      "outputs": [],
      "source": [
        "# Author: Akira Kudo\n",
        "# Created: -\n",
        "# Last updated: 2024/03/10\n",
        "\n",
        "# Given the cursor movement sample rates seems lower than 1000Hz,\n",
        "# identify sample rate for cursor movement\n",
        "\n",
        "# first define useful functions\n",
        "# Counts the number of consecutive true / false blocks\n",
        "def count_consecutive_true_or_false_block_sizes(arr, countTrue):\n",
        "  # find positions where a new block begins\n",
        "  block_start = np.concatenate(([True], arr[:-1] != arr[1:]))\n",
        "  # get block lengths based on that\n",
        "  block_lengths = np.diff(\n",
        "      np.append( np.where(block_start)[0], len(arr))\n",
        "      )\n",
        "  # count block sizes of interest\n",
        "  count_start = 0 if (countTrue == arr[0]) else 1\n",
        "  counting_block_sizes = block_lengths[count_start::2]\n",
        "  return counting_block_sizes\n",
        "\n",
        "def SanityCheck_count_consecutive_true_or_false_block_sizes():\n",
        "  block_sizes = [3,2,5,1,20,3]; initial_val = False\n",
        "  initial_val_blocks = [3,5,20]; opposite_val_blocks = [2,1,3]\n",
        "  arr = np.concatenate(\n",
        "      [np.array([i % 2 != 0] * block_sizes[i])\n",
        "      for i in range(0, len(block_sizes))]\n",
        "  )\n",
        "  np.testing.assert_array_equal(opposite_val_blocks,\n",
        "      count_consecutive_true_or_false_block_sizes(arr, not initial_val))\n",
        "  np.testing.assert_array_equal(initial_val_blocks,\n",
        "      count_consecutive_true_or_false_block_sizes(arr, initial_val))\n",
        "\n",
        "SanityCheck_count_consecutive_true_or_false_block_sizes()\n",
        "\n",
        "# then use it\n",
        "def check_window_sizes(patient_num):\n",
        "  print(f\"PATIENT {patient_num}: \")\n",
        "  def check_for_window_size_given_one_array(arr):\n",
        "    # indices at which values are different from immediate previous\n",
        "    # * 1st entry is considered different\n",
        "    block_starts = np.insert(np.ediff1d(arr).astype(bool), 0, True)\n",
        "\n",
        "    likely_window_sizes = count_consecutive_true_or_false_block_sizes(block_starts, False) + 1\n",
        "    unique_window_sizes = np.unique(likely_window_sizes)\n",
        "    print(\"Unchanging window sizes found: \\n\", unique_window_sizes)\n",
        "    # at this point, we can see that values are all multiples of 40\n",
        "    assert np.prod(np.mod(unique_window_sizes, 40) == 0) == 1, \\\n",
        "           f\"Some window size for patient {patient_num} isn't a multiple of 40: \" + \\\n",
        "           f\"{arr}.\"\n",
        "\n",
        "  cursorX = alldat[0][patient_num][\"cursorX\"]\n",
        "  cursorY = alldat[0][patient_num][\"cursorY\"]\n",
        "  targetX = alldat[0][patient_num][\"targetX\"]\n",
        "  targetY = alldat[0][patient_num][\"targetY\"]\n",
        "\n",
        "  check_for_window_size_given_one_array(cursorX)\n",
        "  check_for_window_size_given_one_array(cursorY)\n",
        "  check_for_window_size_given_one_array(targetX)\n",
        "  check_for_window_size_given_one_array(targetY)\n",
        "\n",
        "for patient_num in range(len(alldat[0])):\n",
        "  check_window_sizes(patient_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD6Zcul1lfsd"
      },
      "source": [
        "## Dataset Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2fJYP2-lfsd"
      },
      "source": [
        "### Joystick Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrs-8jw1lfsd"
      },
      "outputs": [],
      "source": [
        "# plot cursor data\n",
        "dat = alldat[0][0]\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(dat['cursorX'], label='cursorX')\n",
        "plt.plot(dat['targetX'], label='targetX')\n",
        "plt.title('cursor and target over time (X direction)')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(dat['cursorY'], label='cursorY')\n",
        "plt.plot(dat['targetY'], label='targetY')\n",
        "plt.title('cursor and target over time (Y direction)')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvDv1vMPlfse"
      },
      "outputs": [],
      "source": [
        "plt.figure(3, figsize=(8, 8))\n",
        "plt.plot(dat['cursorX'][:10000], dat['cursorY'][:10000], label='cursor')\n",
        "plt.plot(dat['targetX'][:10000], dat['targetY'][:10000], label='target')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.title('first 10000 time steps')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nV0peV3lfse"
      },
      "outputs": [],
      "source": [
        "# Author: Akira Kudo\n",
        "# Created: -\n",
        "# Last updated: 2024/03/10\n",
        "\n",
        "CALCULATION_DATATYPE = np.float32\n",
        "\n",
        "# Add labels based on X, Y directions of cursor at each point in time\n",
        "# At each time point, the cursor position is simulated as:\n",
        "# 1) direction as the direction from current position to next position\n",
        "# 2) distance from center as speed between time points\n",
        "# 2's definition is quite arbitrary - but we believe it is not an issue,\n",
        "# given we only consider the overall stick direction 1 as label.\n",
        "# Returns speed and direction (counter-clockwise starting from east direction\n",
        "# in radians) between each time point\n",
        "def get_speed_and_direction(cursorX : np.ndarray, cursorY : np.ndarray,\n",
        "                            xLimits=( float(\"-inf\"), float(\"inf\")),\n",
        "                            yLimits=( float(\"-inf\"), float(\"inf\"))):\n",
        "  if type(xLimits) not in [type([]), type(())] or len(xLimits) != 2:\n",
        "    print(\"xLimits must be a list/tuple with length 2; try again!\")\n",
        "    return\n",
        "  elif type(yLimits) not in [type([]), type(())] or len(yLimits) != 2:\n",
        "    print(\"yLimits must be a list/tuple with length 2; try again!\")\n",
        "    return\n",
        "  else:\n",
        "    xUpperbound = max(xLimits); xLowerbound = min(xLimits)\n",
        "    yUpperbound = max(yLimits); yLowerbound = min(yLimits)\n",
        "\n",
        "  cursorX = cursorX.astype(CALCULATION_DATATYPE)\n",
        "  cursorY = cursorY.astype(CALCULATION_DATATYPE)\n",
        "  # filter based on x/y limits\n",
        "  cursorX[(cursorX > xUpperbound) | (cursorX < xLowerbound)] = np.nan\n",
        "  cursorY[(cursorY > yUpperbound) | (cursorY < yLowerbound)] = np.nan\n",
        "  # compute speed & direction between each time point\n",
        "  diffX = np.ediff1d(cursorX); diffY = np.ediff1d(cursorY)\n",
        "  speedSq = np.square(diffX) + np.square(diffY)\n",
        "  speed = np.sqrt(speedSq)\n",
        "  # direction\n",
        "  direction = np.arctan2(diffY, diffX)\n",
        "  direction = np.mod(direction + 2*np.pi, 2*np.pi) # 0 <= dir <= 2pi\n",
        "  return speed, direction\n",
        "\n",
        "def SanityCheck_get_speed_and_direction():\n",
        "  # try 30, 45, 60, 120, 135, 150, 210, 225, 240, 300, 315 and 330 degrees\n",
        "  PI = np.pi; angles = [  PI/6,   PI/4, 2*PI/6,  4*PI/6, 3*PI/4,  5*PI/6,\n",
        "                        7*PI/6, 5*PI/4, 8*PI/6, 10*PI/6, 7*PI/4, 11*PI/6]\n",
        "  # try 1, 2 and 3 speeds\n",
        "  distances = [1,2,3]\n",
        "\n",
        "  for angle in angles:\n",
        "    for distance in distances:\n",
        "      x = np.array([0, distance*np.cos(angle)]).astype(CALCULATION_DATATYPE)\n",
        "      y = np.array([0, distance*np.sin(angle)]).astype(CALCULATION_DATATYPE)\n",
        "      speed, direction = get_speed_and_direction(x, y)\n",
        "      np.testing.assert_almost_equal(distance,  speed, decimal=5)\n",
        "      np.testing.assert_almost_equal(angle, direction, decimal=5)\n",
        "\n",
        "SanityCheck_get_speed_and_direction()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rNH3zj-lfse"
      },
      "outputs": [],
      "source": [
        "# Author: Akira Kudo\n",
        "# Created: -\n",
        "# Last updated: 2024/03/10\n",
        "\n",
        "# Plots joy stick position over time, with points progressively increasing in\n",
        "# shade darkness for later time points\n",
        "def plot_figure_over_time(X : np.ndarray, Y : np.ndarray,\n",
        "                          start : int, end : int, figureName : str):\n",
        "  blueColor = plt.cm.Blues(np.linspace(0.1,1,(end-start)))\n",
        "  fig,ax = plt.subplots(figsize=(6,6))\n",
        "  for k in range(end - start):\n",
        "    if k + 1 > len(X): break\n",
        "    ax.plot(X[k:k+2], Y[k:k+2], color=blueColor[k])\n",
        "  plt.xlabel('X'); plt.ylabel('Y')\n",
        "  plt.title(figureName)\n",
        "  plt.xlim(np.nanmin(X), np.nanmax(X)); plt.ylim(np.nanmin(Y), np.nanmax(Y))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwD-tbHJlfsf"
      },
      "outputs": [],
      "source": [
        "# Author: Akira Kudo\n",
        "# Created: -\n",
        "# Last updated: 2024/03/10\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import math\n",
        "\n",
        "# Plots and saves a gif of the change of an object's X/Y position over time\n",
        "# X/Y : List of plot data over time\n",
        "# plot_every_n : Plot 1 every N values of the X, Y inputs.\n",
        "# figurepath : path to saving for gif, including name and extension\n",
        "# doSave : whether to save the gif\n",
        "# addProgressBar : whether to add a \"progress bar\" rendering\n",
        "def plot_and_save_gif(X, Y, plot_every_n : int, figurepath : str,\n",
        "                      doSave : bool=True, addProgressBar : bool = True,\n",
        "                      trail_length : int = None):\n",
        "\n",
        "  xLowerbound, xUpperbound = np.nanmin(X), np.nanmax(X)\n",
        "  yLowerbound, yUpperbound = np.nanmin(Y), np.nanmax(Y)\n",
        "  # Calculate how often we plot\n",
        "  number_of_rendered_frames = len(X) // plot_every_n\n",
        "  # Create the figure and axes objects\n",
        "  fig, ax = plt.subplots(figsize=(6,6))\n",
        "  # Set the initial plot\n",
        "  plt.title(f\"{os.path.basename(figurepath)}\")\n",
        "  plt.xlim(xLowerbound, xUpperbound)\n",
        "  plt.ylim(yLowerbound, yUpperbound)\n",
        "  data = ax.plot(X[0], Y[0], animated=True)[0]\n",
        "\n",
        "  # Set up progress bar\n",
        "  if addProgressBar:\n",
        "    progressBarXMin = -0.8; progressBarXMax = 0.8; progressBarY = -0.8\n",
        "\n",
        "    progressBarMiddle = (progressBarXMax + progressBarXMin) / 2\n",
        "    progressBar = ax.plot(progressBarXMin, progressBarY, animated=True)[0]\n",
        "    progressBarX = [(progressBarXMax - progressBarXMin) / number_of_rendered_frames * x -\n",
        "                    progressBarXMin\n",
        "                    for x in range(number_of_rendered_frames)]\n",
        "\n",
        "  def update(i):\n",
        "      plot_up_to = min(i * plot_every_n, len(X))\n",
        "\n",
        "      if trail_length is None:\n",
        "        plot_from = 0\n",
        "      else:\n",
        "        plot_from = max(plot_up_to - trail_length, 0)\n",
        "\n",
        "      data.set_data(X[plot_from:plot_up_to], Y[plot_from:plot_up_to])\n",
        "\n",
        "      if addProgressBar:\n",
        "        progressBar.set_data(progressBarX[:i], [progressBarY]*i)\n",
        "        return (data, progressBar)\n",
        "      else:\n",
        "        return (data,)\n",
        "\n",
        "  # Create the animation object\n",
        "  animation_fig = animation.FuncAnimation(\n",
        "      fig, update, frames=math.ceil(len(X) / plot_every_n), interval=30,\n",
        "      blit=True, repeat_delay=10\n",
        "      )\n",
        "\n",
        "  # Show the animation\n",
        "  plt.show()\n",
        "  if doSave:\n",
        "    animation_fig.save(figurepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNgxd-Helfsf"
      },
      "outputs": [],
      "source": [
        "# Author: Akira Kudo\n",
        "# Created: -\n",
        "# Last updated: 2024/03/10\n",
        "\n",
        "# Plots and saves a gif of the change of the cursor and joystick X/Y position\n",
        "# over time\n",
        "# cursorX/cursorY : List of cursor plot data over time\n",
        "# joystickX/joystickY : List of joystick plot data over time\n",
        "# plot_every_n : Plot 1 every N values of the X, Y inputs.\n",
        "# figurepath : path to saving for gif, including name and extension\n",
        "# doSave : whether to save the gif\n",
        "# addProgressBar : whether to add a \"progress bar\" rendering\n",
        "def plot_and_save_cursor_and_joystick_gif(cursorX, cursorY, joystickX, joystickY,\n",
        "                                          plot_every_n : int, figurepath : str,\n",
        "                                          doSave : bool=True,\n",
        "                                          addProgressBar : bool = True,\n",
        "                                          trail_length : int = None):\n",
        "\n",
        "  xCursorLowerbound, xCursorUpperbound = np.nanmin(cursorX), np.nanmax(cursorX)\n",
        "  yCursorLowerbound, yCursorUpperbound = np.nanmin(cursorY), np.nanmax(cursorY)\n",
        "  xJoystickLowerbound, xJoystickUpperbound = np.nanmin(joystickX), np.nanmax(joystickX)\n",
        "  yJoystickLowerbound, yJoystickUpperbound = np.nanmin(joystickY), np.nanmax(joystickY)\n",
        "  # Calculate how often we plot\n",
        "  assert len(cursorX) == len(cursorY)\n",
        "  assert len(joystickX) == len(joystickY)\n",
        "  totalOriginalFrames = max(len(cursorX), len(joystickX))\n",
        "  number_of_rendered_frames = totalOriginalFrames // plot_every_n\n",
        "  # Create the figure and axes objects\n",
        "  fig, (c_ax, j_ax) = plt.subplots(nrows=1, ncols=2, figsize=(12,6))\n",
        "  plt.title(f\"{os.path.basename(figurepath)}\")\n",
        "  # Set the initial cursor plot\n",
        "  c_ax.set_xlim(xCursorLowerbound, xCursorUpperbound)\n",
        "  c_ax.set_ylim(yCursorLowerbound, yCursorUpperbound)\n",
        "  c_data = c_ax.plot(cursorX[0], cursorY[0], animated=True)[0]\n",
        "  # Set the initial joystick plot\n",
        "  j_ax.set_xlim(xJoystickLowerbound, xJoystickUpperbound)\n",
        "  j_ax.set_ylim(yJoystickLowerbound, yJoystickUpperbound)\n",
        "  j_data = j_ax.plot(joystickX[0], joystickY[0], animated=True)[0]\n",
        "\n",
        "  # Set up progress bar\n",
        "  if addProgressBar:\n",
        "    progressBarXMin = -0.8; progressBarXMax = 0.8; progressBarY = -0.8\n",
        "    progressBar = j_ax.plot(progressBarXMin, progressBarY, animated=True)[0]\n",
        "    progressBarX = [(progressBarXMax - progressBarXMin) /\n",
        "                    number_of_rendered_frames * x +\n",
        "                    progressBarXMin\n",
        "                    for x in range(number_of_rendered_frames)]\n",
        "\n",
        "  def update(i):\n",
        "      plot_up_to = min(i * plot_every_n, totalOriginalFrames)\n",
        "\n",
        "      if trail_length is None:\n",
        "        plot_from = 0\n",
        "      else:\n",
        "        plot_from = max(plot_up_to - trail_length, 0)\n",
        "\n",
        "      c_data.set_data(  cursorX[plot_from:plot_up_to],   cursorY[plot_from:plot_up_to])\n",
        "      j_data.set_data(joystickX[plot_from:plot_up_to], joystickY[plot_from:plot_up_to])\n",
        "      if addProgressBar:\n",
        "        progressBar.set_data(progressBarX[:i], [progressBarY]*i)\n",
        "        return (c_data, j_data, progressBar)\n",
        "      else:\n",
        "        return (c_data, j_data)\n",
        "\n",
        "  # Create the animation object\n",
        "  animation_fig = animation.FuncAnimation(\n",
        "      fig, update, frames=math.ceil(totalOriginalFrames / plot_every_n),\n",
        "      interval=100, blit=True, repeat_delay=10\n",
        "      )\n",
        "\n",
        "  # Show the animation\n",
        "  plt.show()\n",
        "  if doSave:\n",
        "    animation_fig.save(figurepath)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Author: Akira Kudo\n",
        "# Created: -\n",
        "# Last updated: 2024/03/10\n",
        "\n",
        "# Define a standardized way of processing cursor data, so as to obtain labels\n",
        "# from them\n",
        "def process_cursor_data(patient_data, label_binsize : int):\n",
        "  cursorX = patient_data[\"cursorX\"][::label_binsize]\n",
        "  cursorY = patient_data[\"cursorY\"][::label_binsize]\n",
        "  # set ledges so that we exclude joystick position when cursor reaches\n",
        "  # ledges of screen\n",
        "  ledgesX = (np.nanmin(cursorX)+1, np.nanmax(cursorX)-1)\n",
        "  ledgesY = (np.nanmin(cursorY)+1, np.nanmax(cursorY)-1)\n",
        "\n",
        "  speed, direction = get_speed_and_direction(\n",
        "      cursorX, cursorY, xLimits=ledgesX, yLimits=ledgesY\n",
        "      )\n",
        "  # ARBITRARY REMOVAL OF VALUES OF SPEED OVER 10000; THIS MAKES THE GRAPH MUCH\n",
        "  # MORE EASY TO UNDERSTAND\n",
        "  speed[speed > 10000] = 0\n",
        "  norm_speed = speed / np.nanmax(speed) # normalize between 0 and 1\n",
        "\n",
        "  # plt.hist(speed)\n",
        "  # plt.yscale('log')\n",
        "  # plt.show\n",
        "\n",
        "  # compute position of joy stick from speed & direction\n",
        "  joystickX = norm_speed * np.cos(direction)\n",
        "  joystickY = norm_speed * np.sin(direction)\n",
        "\n",
        "  return speed, direction, joystickX, joystickY"
      ],
      "metadata": {
        "id": "rUe6Onj-Q1IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxPzQCPglfsf"
      },
      "outputs": [],
      "source": [
        "# Plot joystick and cursor position side by side\n",
        "\n",
        "# SETUP\n",
        "start = 0\n",
        "end = start + 3000\n",
        "\n",
        "patient = alldat[0][0]\n",
        "cursorX = patient[\"cursorX\"][::TIMEPOINTS_PER_CURSOR_UPDATE]\n",
        "cursorY = patient[\"cursorY\"][::TIMEPOINTS_PER_CURSOR_UPDATE]\n",
        "\n",
        "speed, direction, joystickX, joystickY = process_cursor_data(\n",
        "    patient_data=patient,\n",
        "    label_binsize=TIMEPOINTS_PER_CURSOR_UPDATE)\n",
        "\n",
        "end = min(end, len(speed))\n",
        "\n",
        "# PLOT\n",
        "plot_figure_over_time(\n",
        "    joystickX, joystickY, start, end,\n",
        "    f'{start} to {min(end, len(joystickY))} time steps joystick position'\n",
        "    )\n",
        "\n",
        "# # rendering only joystick\n",
        "# FIGURE_PATH = \"joystick_movement.gif\"\n",
        "# plot_and_save_gif(joystickX[start:end], joystickY[start:end],\n",
        "#                   plot_every_n=10, figurepath=FIGURE_PATH, doSave=True,\n",
        "#                   addProgressBar=True, trail_length=10*10)\n",
        "# # rendering both cursor and joystick\n",
        "# FIGURE_PATH = \"cursor_and_joystick_movement.gif\"\n",
        "# plot_and_save_cursor_and_joystick_gif(\n",
        "#       cursorX[start:end],   cursorY[start:end],\n",
        "#     joystickX[start:end], joystickY[start:end],\n",
        "#     plot_every_n=10, figurepath=FIGURE_PATH, doSave=True,\n",
        "#     addProgressBar=True, trail_length=10*10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJviAK-Wlfsg"
      },
      "source": [
        "### ECoG Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfSLFiillfsg"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Labeling\n",
        "\n",
        "What we need to get decided:\n",
        "\n",
        "1.   What processing to further do on the data of format ```[patient x electrode x channel x time]```, aka general processing?\n",
        "\n",
        "2.   What features to extract (and how) from those features? e.g. Binning, feature extraction based on correlation, calculation of general features like local motor potential\n",
        "\n",
        "3. How to put those into a dataset that is loadable into pytorch? Pytorch customizable dataloaders can really load any format - maybe a numpy file is appropriate for our case. -> store post-processing datasets in the form of ```[patient x feature x bins]```, with labels, ready to be loaded?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pcWgOp_HryOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Author: Akira Kudo\n",
        "# Created: -\n",
        "# Last updated: 2024/03/10\n",
        "\n",
        "# TRIAL IMPLEMENTATION OF CUSTOM DATASET WILL COME HERE\n",
        "# USING [https://pytorch.org/tutorials/beginner/basics/data_tutorial.html] AS EXAMPLE\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def bin_data_to_binsize(data : Dict,\n",
        "                        binsize : int,\n",
        "                        stepsize : int,\n",
        "                        show_conversion : bool = False):\n",
        "  \"\"\"\n",
        "  Bins numpy arrays given as dictinary of data into given bin sizes\n",
        "  e.g. for a time series of [n x m] and bin size k and step size l, we produce a\n",
        "       [num_bins x k x m] array with entries ready for analysis\n",
        "       Here, num_bins = (n - k) // l + 1\n",
        "  \"\"\"\n",
        "  returned = {}\n",
        "\n",
        "  if binsize % TIMEPOINTS_PER_CURSOR_UPDATE != 0:\n",
        "    print(f\"You specified bin datasize {binsize} which isn't a multiple of \" +\n",
        "          f\"the frequency of cursor update that is {TIMEPOINTS_PER_CURSOR_UPDATE}. \")\n",
        "\n",
        "  if binsize < TIMEPOINTS_PER_CURSOR_UPDATE:\n",
        "    print(f\"You specified bin datasize {binsize} which is smaller than \" +\n",
        "          f\"the frequency of cursor update that is {TIMEPOINTS_PER_CURSOR_UPDATE}. \")\n",
        "    print(\"Labels associated to this binning might not have a meaningful interpretation.\")\n",
        "\n",
        "  for key, d in data.items():\n",
        "    binned_d = bin_array_using_binsize_and_stepsize(arr=d,\n",
        "                                                    binsize=binsize,\n",
        "                                                    stepsize=stepsize)\n",
        "    returned[f'{key}_binned'] = binned_d\n",
        "\n",
        "    if show_conversion:\n",
        "      print(f\"After reshaping: {binned_d.shape}\")\n",
        "      print(f\"Before reshaping: {d.shape}\")\n",
        "\n",
        "  return returned\n",
        "\n",
        "\n",
        "# Helper\n",
        "def bin_array_using_binsize_and_stepsize(arr : np.ndarray,\n",
        "                                         binsize : int,\n",
        "                                         stepsize : int):\n",
        "    arrsz = arr.shape[0]\n",
        "    # e.g. with array [1,2,3,4,5,6] and binsize=3, stepsize=2, bins are:\n",
        "    #      [1,2,3], [3,4,5] making truncated array size 5 = (6 - 3) // 2 * 2 + 3\n",
        "    arrsz = (arrsz - binsize) // stepsize * stepsize + binsize # rounding to nearest number of bins, truncating rest\n",
        "    arr = arr[:arrsz, ...] # truncate to nearest possible bin size\n",
        "\n",
        "    # if binsize is equal to stepsize, reshape (for fast performance?)\n",
        "    if binsize == stepsize:\n",
        "      newshape = (arrsz // binsize, binsize) + arr.shape[1:]\n",
        "      binned = arr.reshape(newshape)\n",
        "    else:\n",
        "      arr_list = []\n",
        "      for binstart in range(0, arrsz, stepsize):\n",
        "        # if entire bin is within arrsz range\n",
        "        binend = binstart + binsize - 1\n",
        "        if (binend + 1) <= arrsz:\n",
        "          arr_list.append(arr[binstart:binend+1])\n",
        "      binned = np.stack(arr_list, axis=0)\n",
        "\n",
        "    return binned\n",
        "\n",
        "def sanity_check_bin_data_to_binsize():\n",
        "  binsize = TIMEPOINTS_PER_CURSOR_UPDATE * 2\n",
        "  stepsize = TIMEPOINTS_PER_CURSOR_UPDATE // 2\n",
        "  # stepsize = TIMEPOINTS_PER_CURSOR_UPDATE * 2\n",
        "  binned_data = []\n",
        "\n",
        "  # for each patient index (0~3?)\n",
        "  for i, patient in enumerate(alldat[0]):\n",
        "    # likely useful labels: 'V', 'targetX/Y', 'cursorX/Y'\n",
        "    label_to_bin = ['V']\n",
        "    tobin = dict([ (key, patient[key]) for key in label_to_bin])\n",
        "    binned = bin_data_to_binsize(tobin, binsize, stepsize)\n",
        "    binned_data.append(binned)\n",
        "\n",
        "  print(f\"Chose bin size of {binsize} and step size of {stepsize}!\")\n",
        "  [print(f\"patient {i}:\", [f\"{key} - {patient[key].shape}\" for key in patient.keys()])\n",
        "  for i, patient in enumerate(binned_data)]\n",
        "\n",
        "  # also sanity check with a simple array\n",
        "  # [1,2,3,4,5,6], stepsize=2, binsize=3 -> [1,2,3], [3,4,5]\n",
        "  simple_array = np.array([[1,1],[2,2],[3,3],[4,4],[5,5],[6,6]])\n",
        "  binned = bin_data_to_binsize({'simple_arr' : simple_array}, binsize=3, stepsize=2)\n",
        "  # compare expected and actual\n",
        "  expected_binned = np.array([\n",
        "      [[1,1],[2,2],[3,3]],\n",
        "      [[3,3],[4,4],[5,5]]\n",
        "      ])\n",
        "  actual_binned = binned['simple_arr_binned']\n",
        "  assert np.array_equal(expected_binned, actual_binned), \"Result from bin_data_to_binsize was unexpected...\"\n",
        "  print(\"{}: {}\".format(*list(binned.items())[0]))\n",
        "\n",
        "sanity_check_bin_data_to_binsize()"
      ],
      "metadata": {
        "id": "ED0g8wnFr8J8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Author: Akira Kudo\n",
        "# Created: -\n",
        "# Last updated: 2024/03/10\n",
        "\n",
        "# we divide the field into four quadrants; each quadrant is centered around\n",
        "# the four directions, 1:right, 2:up, 3:left, 4:down.\n",
        "def label_quadrant(speed : np.ndarray, direction : np.ndarray):\n",
        "  # TODO - DO SOMETHING WITH SPEED!!\n",
        "  def angle_to_quadrant(direction):\n",
        "    if 0 <= direction <= np.pi/4:\n",
        "      quadrant = 1\n",
        "    elif np.pi/4 < direction <= np.pi*3/4:\n",
        "      quadrant = 2\n",
        "    elif np.pi*3/4 < direction <= np.pi*5/4:\n",
        "      quadrant = 3\n",
        "    elif np.pi*5/4 < direction <= np.pi*7/4:\n",
        "      quadrant = 4\n",
        "    else:\n",
        "      quadrant = 1\n",
        "    return quadrant\n",
        "\n",
        "  labels = np.vectorize(angle_to_quadrant)(direction)\n",
        "  return labels\n",
        "\n",
        "def sanity_check_plot_labels_by_quadrant(X : np.ndarray,\n",
        "                                         Y : np.ndarray,\n",
        "                                         label : np.ndarray,\n",
        "                                         figureName : str):\n",
        "  fig = plt.figure(figsize=(6,6))\n",
        "  colors = [None, 'b', 'g', 'r', 'k']\n",
        "  for quadrant in range(1,5):\n",
        "    quad_lbl_idx = label==quadrant\n",
        "    plt.plot(X[quad_lbl_idx], Y[quad_lbl_idx], color=colors[quadrant])\n",
        "  plt.xlabel('X'); plt.ylabel('Y')\n",
        "  plt.title(figureName)\n",
        "  plt.xlim(np.nanmin(X), np.nanmax(X)); plt.ylim(np.nanmin(Y), np.nanmax(Y))\n",
        "  plt.show()\n",
        "\n",
        "label = label_quadrant(speed, direction)\n",
        "sanity_check_plot_labels_by_quadrant(joystickX, joystickY, label, figureName=\"Plot by quadrants\")"
      ],
      "metadata": {
        "id": "ehw8KFycl0s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Author: Akira Kudo\n",
        "# Created: -\n",
        "# Last updated: 2024/03/10\n",
        "def get_label_consistency_of_binsize(cursorX : np.ndarray,\n",
        "                                     cursorY : np.ndarray,\n",
        "                                     binsize  : int=TIMEPOINTS_PER_CURSOR_UPDATE,\n",
        "                                     max_multiple : int=10):\n",
        "  \"\"\"\n",
        "  For bin sizes that are up to 'max_multiple' multiple, calculate what fraction\n",
        "  of the bin is consistent in label.\n",
        "  :param np.ndarray cursorX: X cursor position extracted from the dataset.\n",
        "  :param np.ndarray cursorY: Y cursor position extracted from the dataset.\n",
        "  :param int binsize: Size of bin that is the minimum bin size we investigate.\n",
        "  :param int max_multiple: Investigate (i * 'binsize') bin sizes, where i is\n",
        "  between 2 and max_multiple inclusive.\n",
        "  \"\"\"\n",
        "  # first extract labels using binsize\n",
        "  speed, direction, joystickX, joystickY = process_cursor_data(\n",
        "    patient_data= { \"cursorX\" : cursorX, \"cursorY\" : cursorY},\n",
        "    label_binsize=binsize)\n",
        "\n",
        "  labels = label_quadrant(speed, direction)\n",
        "  consistent_proportions = []\n",
        "  # then check for multiples of binsize whether the labels match within bins\n",
        "  for multiplier in range(2, max_multiple+1):\n",
        "    consistent_bin_count = 0\n",
        "    # bin the label\n",
        "    labels_per_position_in_bin = bin_array_using_binsize_and_stepsize(\n",
        "        arr=labels, binsize=multiplier, stepsize=multiplier)\n",
        "\n",
        "    # count the number of consistent bins\n",
        "    for i in range(labels_per_position_in_bin.shape[0]):\n",
        "      # if bin is consistent\n",
        "      if np.all(labels_per_position_in_bin[i,0] == labels_per_position_in_bin[i,0:]):\n",
        "        consistent_bin_count += 1\n",
        "    # compute the ratio of consistent bins to the total\n",
        "    consistent_proportions.append(consistent_bin_count / labels_per_position_in_bin.shape[0])\n",
        "\n",
        "  return consistent_proportions"
      ],
      "metadata": {
        "id": "0Q3kauBky94_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patient = alldat[0][0]\n",
        "cursorX, cursorY = patient[\"cursorX\"], patient[\"cursorY\"]\n",
        "consistent_ratio = get_label_consistency_of_binsize(cursorX, cursorY, binsize=40)\n",
        "print(consistent_ratio)"
      ],
      "metadata": {
        "id": "IcGG-5XUCY7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Author: Akira Kudo\n",
        "# Created: -\n",
        "# Last updated: 2024/03/10\n",
        "def save_npz_bins_and_labels_for_all_patients(original_dataset,\n",
        "                                              savedir : str,\n",
        "                                              filename : str=\"binned_V_and_label\",\n",
        "                                              V_binsize     : int=TIMEPOINTS_PER_CURSOR_UPDATE,\n",
        "                                              V_stepsize    : int=TIMEPOINTS_PER_CURSOR_UPDATE,\n",
        "                                              label_binsize : int=TIMEPOINTS_PER_CURSOR_UPDATE):\n",
        "  \"\"\"\n",
        "  Create a npz holding both binned data and their labels for all patients.\n",
        "  Voltage data will be binned according to both bin and step size.\n",
        "  A corresponding label array is provided, where a label is applied to the nth\n",
        "  voltage bin only if it is consistent within the duration, and otherwise a -1\n",
        "  label is applied.\n",
        "  :param dict original_dataset: The original dataset, as extracted from\n",
        "  joystick_track.npz.\n",
        "  :param str savedir: Directory to save the results to.\n",
        "  :param str filename: Name of the file we save the result as, which will be\n",
        "  suffixed with '_Vb{V_binsize}_Vs{V_stepsize}_l{label_binsize}'.\n",
        "  :param int V_binsize: The size to which we bin voltage data into. Must be a\n",
        "  multiple of label_binsize. Defaults to TIMEPOINTS_PER_CURSOR_UPDATE, and must\n",
        "  not be smaller.\n",
        "  :param int V_stepsize: The step size between two consecutive voltage data bins.\n",
        "  Must be a multiple of label_binsize. Defaults to TIMEPOINTS_PER_CURSOR_UPDATE,\n",
        "  and must not be smaller.\n",
        "  :param int label_binsize: The number of timesteps between two consecutive\n",
        "  cursor timepoints we use to identify the corresponding label. Recommended to\n",
        "  leave as default, TIMEPOINTS_PER_CURSOR_UPDATE, and must not be smaller.\n",
        "  \"\"\"\n",
        "  if V_binsize % label_binsize != 0:\n",
        "    raise Exception(f\"V_binsize {V_binsize} must be a multiple of label_binsize {label_binsize}!\")\n",
        "  if V_stepsize % label_binsize != 0:\n",
        "    raise Exception(f\"V_stepsize {V_stepsize} must be a multiple of label_binsize {label_binsize}!\")\n",
        "\n",
        "  toNpz_dict = {}\n",
        "\n",
        "  for i, patient in enumerate(original_dataset[0]):\n",
        "    # extract labels first\n",
        "    speed, direction, joystickX, joystickY = process_cursor_data(\n",
        "        patient_data=patient,\n",
        "        label_binsize=label_binsize)\n",
        "    label = label_quadrant(speed, direction)\n",
        "\n",
        "    # then bin it according to binsize and stepsize\n",
        "    labels_per_Vbin, labels_per_Vstep = V_binsize // label_binsize, V_stepsize // label_binsize\n",
        "    binned_label = bin_array_using_binsize_and_stepsize(arr=label,\n",
        "                                                        binsize=labels_per_Vbin,\n",
        "                                                        stepsize=labels_per_Vstep)\n",
        "    # labels consistent within a bin are preserved, and non-consistent bins are\n",
        "    # labeled as -1\n",
        "    consistent_label = []\n",
        "    for i in range(binned_label.shape[0]):\n",
        "      # if bin is consistent, keep the label\n",
        "      if np.all(binned_label[i,0] == binned_label[i,0:]):\n",
        "        consistent_label.append(binned_label[i,0])\n",
        "      # if bin isn't consistent, label it with -1\n",
        "      else:\n",
        "        consistent_label.append(-1)\n",
        "    consistent_label = np.array(consistent_label)\n",
        "\n",
        "    toNpz_dict[f\"patient_{i}_label\"] = consistent_label\n",
        "    # also bin dataset into the according format\n",
        "    label_to_bin = ['V']\n",
        "    tobin = dict([ (key, patient[key]) for key in label_to_bin])\n",
        "    V_binned = bin_data_to_binsize(tobin, V_binsize, V_stepsize, show_conversion=True)\n",
        "\n",
        "    toNpz_dict[f\"patient_{i}_V\"] = V_binned['V_binned']\n",
        "\n",
        "\n",
        "  final_filename = f\"{filename}_Vb{V_binsize}_Vs{V_stepsize}_l{label_binsize}\"\n",
        "  print(f\"Saving {final_filename} under {savedir}.\")\n",
        "  np.savez(os.path.join(savedir, final_filename), **toNpz_dict)\n",
        "  print(\"Successful.\")\n"
      ],
      "metadata": {
        "id": "Fx_vebjbO78H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Actually save an instance of binned data\n",
        "\n",
        "# save computed result\n",
        "SAVE_DIR = \".\"\n",
        "save_npz_bins_and_labels_for_all_patients(\n",
        "    alldat,\n",
        "    savedir=SAVE_DIR,\n",
        "    filename=\"binned_V_and_label\",\n",
        "    V_binsize=40,\n",
        "    V_stepsize=40,\n",
        "    label_binsize=40\n",
        "    )\n",
        "\n",
        "# load and check result\n",
        "npzfile = np.load(\"binned_V_and_label_Vb40_Vs40_l40.npz\")\n",
        "print(f\"npzfile.files: {npzfile.files}\")\n",
        "for f in npzfile.files:\n",
        "  print(f\"npzfile[{f}].shape: {npzfile[f].shape}\")"
      ],
      "metadata": {
        "id": "EKylz4P9UUDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patient = alldat[0][0]\n",
        "\n",
        "speed, direction, joystickX, joystickY = process_cursor_data(\n",
        "    patient_data=patient, label_binsize=TIMEPOINTS_PER_CURSOR_UPDATE)\n",
        "\n",
        "labels = label_quadrant(speed, direction)"
      ],
      "metadata": {
        "id": "Ee8VqiPTjFxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Extraction\n",
        "----------\n",
        "Copying this paper [here](https://iopscience.iop.org/article/10.1088/1741-2552/ac4ed1/pdf):\n",
        "\n",
        "**Lin Yao et al (2022). Fast and accurate decoding of finger movements\n",
        "from ECoG through Riemannian features and\n",
        "modern machine learning techniques**\n",
        "\n",
        "<br>\n",
        "\n",
        "Signal from each electrode are:\n",
        "*   Common average referenced\n",
        "*   Divided into 200 ms epochs with 40 ms steps <- *ROOM FOR TWEAKING*\n",
        "\n",
        "Extracted features:\n",
        "*   alpha (8–13 Hz)\n",
        "*   beta (13–30 Hz)\n",
        "*   low-gamma (30–60 Hz)\n",
        "*   gamma (60–100 Hz)\n",
        "*   high-gamma (100–200 Hz) power\n",
        "*   LMPs - running average of raw ECoG for each channel\n",
        "*   Hjorth activity, mobility & complexity parameters - statistical properties: variance (activity), mean frequency (mobility) & changes in frequency over a given time period (complexity)"
      ],
      "metadata": {
        "id": "5FOYFgBptVK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Author: Akira Kudo\n",
        "# Created: 2024/03/13\n",
        "# Last updated: 2024/03/13\n",
        "\n",
        "def common_average_reference(V_data : np.ndarray, channel_axis : int=-1):\n",
        "    \"\"\"\n",
        "    Computes the common average referenced voltage data, which allows removal\n",
        "    of non-local brain activity to be removed and enhances signals.\n",
        "    For each time point t, the common-average-referenced voltage data for\n",
        "    channel n, t_rn is computed as:\n",
        "    t_rn = t_n - 1/N * (Sum from i=1~N) t_N\n",
        "    where t_n is the raw voltage data from channel n and we have N channels.\n",
        "    :param np.ndarray V_data: Voltage data which we common-average-reference.\n",
        "    :param int channel_axis: The axis that holds the channel dimension.\n",
        "    Defaults to -1.\n",
        "    \"\"\"\n",
        "    common_average = np.mean(V_data, axis=channel_axis, keepdims=True)\n",
        "    cmn_avg_rfr = V_data - common_average\n",
        "    return cmn_avg_rfr\n",
        "\n",
        "def sanity_check_common_averge_reference():\n",
        "   pre_reference  = np.array([[ 0,1,2], [ 1,3,5], [ 4,7,10], [1,1,1]])\n",
        "   post_reference = np.array([[-1,0,1], [-2,0,2], [-3,0, 3], [0,0,0]])\n",
        "   cmn_avg_rfr = common_average_reference(pre_reference)\n",
        "   assert np.array_equal(cmn_avg_rfr, post_reference)\n",
        "   print(f\"Original array: {pre_reference}\")\n",
        "   print(f\"Common-average-referenced: {cmn_avg_rfr}\")\n",
        "\n",
        "sanity_check_common_averge_reference()"
      ],
      "metadata": {
        "id": "8Ycm30O3t2TC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patient = alldat[0][0]\n",
        "\n",
        "plt.plot(patient['V'][:, 0])\n",
        "plt.title(\"First voltage channel for subject 1, session 1\")\n",
        "plt.show()\n",
        "\n",
        "V_cm_avg_ref = common_average_reference(V_data=patient['V'])\n",
        "\n",
        "plt.plot(V_cm_avg_ref[:, 0])\n",
        "plt.title(\"Common-average-referenced first voltage channel for subject 1, session 1\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zh_4SldxPn5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Frequency Features"
      ],
      "metadata": {
        "id": "anhuptvWvHFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Author: Akira Kudo\n",
        "# Created: 2024/03/10\n",
        "# Last updated: 2024/03/14\n",
        "\n",
        "from typing import Tuple\n",
        "\n",
        "# Conversion into frequency domain: can be done 1) by bins, or 2) for whole signal?\n",
        "# My vague understanding: smaller window = sharper signals, but less bands. Using\n",
        "#  larger windows will in turn yield many bands, but fails to capture momentous\n",
        "#  frequencies within the data. So we might wanna focus on smaller bins?\n",
        "#  Source on windowsize: [https://digitalsoundandmusic.com/2-3-10-windowing-the-fft/#:~:text=There's%20a%20tradeoff%20in%20the,size%20N%20is%20N%2F2.]\n",
        "def extract_frequency_features_from_binned_voltage(\n",
        "    binned_V : np.ndarray,\n",
        "    frequency_ranges : Tuple[Tuple[int]]\n",
        "    ):\n",
        "    \"\"\"\n",
        "    Extract frequency features specified under 'frequency_ranges', given an\n",
        "    already binned voltage data. Fast fourier transform is used to convert\n",
        "    individual bins into their frequency domain.\n",
        "    :param np.ndarray binned_V: A binned voltage data array, of shape\n",
        "    [binnumber x binsize x channelsize].\n",
        "    :param Tuple[Tuple[int]] frequency_ranges: A tuple of tuple of integer\n",
        "    expressing the frequency ranges as ((low, high), (low, high), ...) etc.\n",
        "    Corresponding frequency ranges will be extracted, where the size of frequency\n",
        "    bins is determined by the bin size N of voltage data (N/2, if I understand correctly?)\n",
        "\n",
        "    I checked out https://docs.scipy.org/doc/scipy-1.11.4/tutorial/fft.html#d-discrete-fourier-transforms\n",
        "    for understanding how to apply fourier transforms from scipy.\n",
        "    \"\"\"\n",
        "    frequency_result, exact_freq_ranges = [], []\n",
        "\n",
        "    binsize = binned_V.shape[1]\n",
        "    # use rfft as we have real-valued inputs; speed up!\n",
        "    frequency_domain = fft.rfft(binned_V, axis=1)[:,1:,:] # exclude first term which isn't useful??\n",
        "    frequency_bincenters = fft.fftfreq(n=binsize, d=1/SAMPLE_RATE)\n",
        "    # truncate frequency_bincenters given it also returns negative frequency bins\n",
        "    pos_freq_bincenters = frequency_bincenters[frequency_bincenters >= 0]\n",
        "    bin_width = (pos_freq_bincenters[1] - pos_freq_bincenters[0]).item()\n",
        "    bin_start = pos_freq_bincenters[0] - bin_width / 2\n",
        "    # extract requested frequency ranges as the largest set of bins that completely\n",
        "    # fits the requested range. If we cannot fit even a single bin, return the bin\n",
        "    # with most appropriate bin center\n",
        "    for rnglow, rnghigh in frequency_ranges:\n",
        "      idx_bincenter_in_rng_low  = int((rnglow  - pos_freq_bincenters[0]) // bin_width) + 1\n",
        "      idx_bincenter_in_rng_high = int((rnghigh - pos_freq_bincenters[0]) // bin_width)\n",
        "      # if lowest/highest bin that has its center within range doesn't entirely fit\n",
        "      lowest_bin_not_fitting  = (pos_freq_bincenters[idx_bincenter_in_rng_low]  - bin_width / 2) < rnglow\n",
        "      highest_bin_not_fitting = (pos_freq_bincenters[idx_bincenter_in_rng_high] + bin_width / 2) > rnghigh\n",
        "      # deterine which bins are entirely fitting within range\n",
        "      idx_bin_in_rng_low  = idx_bincenter_in_rng_low\n",
        "      idx_bin_in_rng_high = idx_bincenter_in_rng_high\n",
        "      if  lowest_bin_not_fitting:  idx_bin_in_rng_low += 1\n",
        "      if highest_bin_not_fitting: idx_bin_in_rng_high -= 1\n",
        "\n",
        "      # if there is less then one bin fitting\n",
        "      if idx_bin_in_rng_low > idx_bin_in_rng_high:\n",
        "        # find and return the bin with closest bincenter to this range\n",
        "        rngcenter = (rnghigh + rnglow) / 2\n",
        "        if abs(pos_freq_bincenters[idx_bin_in_rng_low]  - rngcenter) < \\\n",
        "           abs(pos_freq_bincenters[idx_bin_in_rng_high] - rngcenter):\n",
        "            idx_closest_bin = idx_bin_in_rng_low\n",
        "        else:\n",
        "            idx_closest_bin = idx_bin_in_rng_high\n",
        "        # get the result\n",
        "        frequency_result.append(\n",
        "            2.0 / binsize * np.abs(\n",
        "                frequency_domain[:,idx_closest_bin : idx_closest_bin+1,:]\n",
        "                )\n",
        "            )\n",
        "        exact_freq_ranges.append(\n",
        "            (pos_freq_bincenters[idx_closest_bin].item() - bin_width / 2,\n",
        "             pos_freq_bincenters[idx_closest_bin].item() + bin_width / 2)\n",
        "            )\n",
        "      else:\n",
        "        frequency_result.append(\n",
        "            2.0 / binsize * np.abs(\n",
        "                frequency_domain[:,idx_bin_in_rng_low : idx_bin_in_rng_high + 1,:]\n",
        "                )\n",
        "            )\n",
        "        exact_freq_ranges.append(\n",
        "            (pos_freq_bincenters[idx_bin_in_rng_low].item()  - bin_width / 2,\n",
        "             pos_freq_bincenters[idx_bin_in_rng_high].item() + bin_width / 2)\n",
        "            )\n",
        "\n",
        "    return frequency_result, exact_freq_ranges"
      ],
      "metadata": {
        "id": "H4fnI9sb0EpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patient = alldat[0][0]\n",
        "label_to_bin = ['V']\n",
        "tobin = dict([ (key, patient[key]) for key in label_to_bin])\n",
        "V_binned = bin_data_to_binsize(tobin, binsize=200, stepsize=40, show_conversion=True)\n",
        "\n",
        "V_binned = V_binned['V_binned']\n",
        "V_cm_avg_ref = common_average_reference(V_data=V_binned)\n",
        "\n",
        "RANGES = ( (8,13),\n",
        "           (13,30),\n",
        "           (30,60),\n",
        "           (60,100),\n",
        "           (100,200) )\n",
        "\n",
        "frequency_result, exact_freq_ranges = extract_frequency_features_from_binned_voltage(binned_V=V_cm_avg_ref, frequency_ranges=RANGES)\n",
        "print(\"Activity bins: \")\n",
        "for res, rng in zip(frequency_result, exact_freq_ranges):\n",
        " print(\"{}:{}\".format(res.shape, rng))\n",
        "\n",
        "plt.plot(frequency_result[0][:,:,0])\n",
        "plt.title(\"Example, frequency bin 0 over time\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mgt3E5Q8JNnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Local Motor Potential (LMP)"
      ],
      "metadata": {
        "id": "plBxUfessRUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Author: Akira Kudo\n",
        "# Created: 2024/03/13\n",
        "# Last updated: 2024/03/14\n",
        "\n",
        "def extract_lmp_from_binned_voltage(binned_V : np.ndarray):\n",
        "    \"\"\"\n",
        "    Extracts the local motor potential feature from binned\n",
        "    voltage data. Local motor potential refers to voltage data\n",
        "    that is amplitude-tuned to cursor movements in the time domain,\n",
        "    i.e. the voltage value over time correlates closely to the\n",
        "    cursor movement over the same time period.\n",
        "    :param np.ndarray binned_V: Binned voltage data,\n",
        "    [num_bins x binsize x num_channels].\n",
        "    :returns np.ndarray lmp: LMP of dimension [num_bins x channels].\n",
        "    \"\"\"\n",
        "    # simply compute the voltage average over bins\n",
        "    lmp = np.mean(binned_V, axis=1)\n",
        "    return lmp"
      ],
      "metadata": {
        "id": "Fd3RflmLsVU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patient = alldat[0][0]\n",
        "label_to_bin = ['V']\n",
        "tobin = dict([ (key, patient[key]) for key in label_to_bin])\n",
        "V_binned = bin_data_to_binsize(tobin, binsize=200, stepsize=40, show_conversion=True)\n",
        "\n",
        "V_binned = V_binned['V_binned']\n",
        "V_cm_avg_ref = common_average_reference(V_data=V_binned)\n",
        "\n",
        "lmp = extract_lmp_from_binned_voltage(binned_V=V_cm_avg_ref)\n",
        "\n",
        "plt.plot(lmp[:, 0])\n",
        "plt.title(\"Example LMP from channel 0 over time\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c9Qj9Fs0Wd-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hjorth Activity, Mobility & Complexity\n"
      ],
      "metadata": {
        "id": "d3sboUBiKCgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Author: Akira Kudo\n",
        "# Created: 2024/03/20\n",
        "# Last Updated: 2024/03/21\n",
        "\n",
        "def extract_Hjorth_features_from_binned_voltage(binned_V : np.ndarray):\n",
        "    \"\"\"\n",
        "    Extracts the Hjorth activity, mobility and complexity features\n",
        "    from binned voltage data.\n",
        "    - Hjorth activity: variance\n",
        "    - Mobility: mean frequency\n",
        "    - Complexity: changes in frequency over a given time period\n",
        "    :param np.ndarray binned_V: Binned voltage data,\n",
        "    [num_bins x binsize x num_channels].\n",
        "    :returns np.ndarray activity, mobility, complexity: Features, each of\n",
        "    dimension [num_bins x channels].\n",
        "    \"\"\"\n",
        "\n",
        "    def extract_Hjorth_activity_from_binned_voltage(binned_V : np.ndarray):\n",
        "      \"\"\"\n",
        "      Extracts the Hjorth activity features from binned voltage data.\n",
        "      Hjorth activity is the variance of signal amplitude per bin.\n",
        "      :param np.ndarray binned_V: Binned voltage data,\n",
        "      [num_bins x binsize x num_channels].\n",
        "      :returns np.ndarray activity: Feature of dim [num_bins x channels].\n",
        "      \"\"\"\n",
        "      # simply return the variance per bins\n",
        "      activity = np.var(binned_V, axis=1)\n",
        "      return activity\n",
        "\n",
        "    def extract_Hjorth_mobility_from_binned_voltage(binned_V : np.ndarray):\n",
        "      \"\"\"\n",
        "      Extracts the Hjorth mobility features from binned voltage data.\n",
        "      Hjorth mobility is computed as the square root of the ratio of\n",
        "       1 - the variance of the first derivative of voltage over time\n",
        "       2 - the variance of voltage amplitude\n",
        "      :param np.ndarray binned_V: Binned voltage data,\n",
        "      [num_bins x binsize x num_channels].\n",
        "      :returns np.ndarray mobility: Feature of dim [num_bins x channels].\n",
        "      \"\"\"\n",
        "      if binned_V.shape[1] < 2:\n",
        "        raise Exception(\"Hjorth mobility can be ill-defined when \" +\n",
        "                      \"the bin size is smaller than 2...\")\n",
        "\n",
        "      voltage_derivative_over_time = np.diff(binned_V, axis=1)\n",
        "\n",
        "      V_derivative_variance = np.var(voltage_derivative_over_time, axis=1)\n",
        "      V_amplitude_variance = np.var(binned_V, axis=1)\n",
        "\n",
        "      mobility_sq = np.divide(V_derivative_variance, V_amplitude_variance)\n",
        "      mobility = np.sqrt(mobility_sq)\n",
        "      return mobility\n",
        "\n",
        "    def extract_Hjorth_complexity_from_binned_voltage(binned_V : np.ndarray):\n",
        "      \"\"\"\n",
        "      Extracts the Hjorth complexity features from binned voltage data.\n",
        "      Hjorth complexity is computed as the ratio of:\n",
        "       1 - Hjorth mobility but computed with variance of the first derivative\n",
        "           of the amplitude signal vs. the second derivative of the signal\n",
        "       2 - Hjorth mobility, computed with amplitude below its first derivative\n",
        "           with respect to time\n",
        "       :param np.ndarray binned_V: Binned voltage data,\n",
        "      [num_bins x binsize x num_channels].\n",
        "      :returns np.ndarray complexity: Feature of dim [num_bins x channels].\n",
        "      \"\"\"\n",
        "      if binned_V.shape[1] < 3:\n",
        "        raise Exception(\"Hjorth complexity can be ill-defined when \" +\n",
        "                      \"the bin size is smaller than 3...\")\n",
        "      voltage_derivative_over_time = np.diff(binned_V, axis=1)\n",
        "      voltage_2nd_derivative_over_time = np.diff(voltage_derivative_over_time, axis=1)\n",
        "      # compute usual mobility first\n",
        "      V_derivative_variance = np.var(voltage_derivative_over_time, axis=1)\n",
        "      V_amplitude_variance = np.var(binned_V, axis=1)\n",
        "      mobility_sq = np.divide(V_derivative_variance, V_amplitude_variance)\n",
        "      mobility = np.sqrt(mobility_sq)\n",
        "      # compute first derivative-based mobility next\n",
        "      V_2nd_derivative_variance = np.var(voltage_2nd_derivative_over_time, axis=1)\n",
        "      first_derivative_mobility_sq = np.divide(V_2nd_derivative_variance, V_derivative_variance)\n",
        "      first_derivative_mobility = np.sqrt(first_derivative_mobility_sq)\n",
        "      # finally compute the ratio\n",
        "      complexity = np.divide(first_derivative_mobility, mobility)\n",
        "      return complexity\n",
        "\n",
        "    activity = extract_Hjorth_activity_from_binned_voltage(binned_V)\n",
        "    mobility = extract_Hjorth_mobility_from_binned_voltage(binned_V)\n",
        "    complexity = extract_Hjorth_complexity_from_binned_voltage(binned_V)\n",
        "\n",
        "    return activity, mobility, complexity"
      ],
      "metadata": {
        "id": "sEmjeB3UzR0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patient = alldat[0][0]\n",
        "label_to_bin = ['V']\n",
        "tobin = dict([ (key, patient[key]) for key in label_to_bin])\n",
        "V_binned = bin_data_to_binsize(tobin, binsize=200, stepsize=40, show_conversion=True)\n",
        "\n",
        "V_binned = V_binned['V_binned']\n",
        "V_cm_avg_ref = common_average_reference(V_data=V_binned)\n",
        "\n",
        "activity, mobility, complexity = extract_Hjorth_features_from_binned_voltage(binned_V=V_cm_avg_ref)\n",
        "\n",
        "for feature, feat_name in zip([activity, mobility, complexity],\n",
        "                              [\"activity\", \"mobility\", \"complexity\"]):\n",
        "  plt.plot(feature[:, 0])\n",
        "  plt.title(f\"Example {feat_name} from channel 0 over time\")\n",
        "  plt.grid()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "uIbVA2q-38w2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}